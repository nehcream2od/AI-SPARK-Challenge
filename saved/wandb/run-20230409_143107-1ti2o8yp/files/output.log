
Sanity Checking: 0it [00:00, ?it/s]
GPU available: False, used: False
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
  | Name          | Type          | Params
------------------------------------------------
0 | generator     | Generator     | 575
1 | discriminator | Discriminator | 89
------------------------------------------------
664       Trainable params
0         Non-trainable params
664       Total params

Epoch 0:   0%|                                                                                                                              | 0/4 [00:00<?, ?it/s]torch.Size([128, 7])
Epoch 0:  25%|█████████                           | 1/4 [00:03<00:11,  3.75s/it, v_num=o8yp, train_generator_loss_step=2.110, train_discriminator_loss_step=0.863]torch.Size([128, 7])
Epoch 0:  50%|██████████████████                  | 2/4 [00:03<00:03,  1.88s/it, v_num=o8yp, train_generator_loss_step=1.980, train_discriminator_loss_step=0.849]torch.Size([89, 7])
Epoch 0:  75%|███████████████████████████         | 3/4 [00:03<00:01,  1.26s/it, v_num=o8yp, train_generator_loss_step=1.890, train_discriminator_loss_step=0.843]

Epoch 1:   0%| | 0/4 [00:00<?, ?it/s, v_num=o8yp, train_generator_loss_step=1.890, train_discriminator_loss_step=0.843, val_discriminator_loss=1.490, val_generatotorch.Size([128, 7])
Epoch 1:  25%|▎| 1/4 [00:18<00:56, 18.73s/it, v_num=o8yp, train_generator_loss_step=1.760, train_discriminator_loss_step=0.847, val_discriminator_loss=1.490, val_torch.Size([128, 7])
Epoch 1:  50%|▌| 2/4 [00:19<00:19,  9.53s/it, v_num=o8yp, train_generator_loss_step=1.640, train_discriminator_loss_step=0.888, val_discriminator_loss=1.490, val_torch.Size([89, 7])
Epoch 1:  75%|▊| 3/4 [00:19<00:06,  6.36s/it, v_num=o8yp, train_generator_loss_step=1.410, train_discriminator_loss_step=0.904, val_discriminator_loss=1.490, val_

Epoch 2:   0%| | 0/4 [00:00<?, ?it/s, v_num=o8yp, train_generator_loss_step=1.410, train_discriminator_loss_step=0.904, val_discriminator_loss=1.600, val_generatotorch.Size([128, 7])
Epoch 2:  25%|▎| 1/4 [00:18<00:56, 18.98s/it, v_num=o8yp, train_generator_loss_step=1.400, train_discriminator_loss_step=0.908, val_discriminator_loss=1.600, val_torch.Size([128, 7])
Epoch 2:  50%|▌| 2/4 [00:18<00:18,  9.50s/it, v_num=o8yp, train_generator_loss_step=1.340, train_discriminator_loss_step=0.869, val_discriminator_loss=1.600, val_torch.Size([89, 7])
Epoch 2:  75%|▊| 3/4 [00:19<00:06,  6.34s/it, v_num=o8yp, train_generator_loss_step=1.250, train_discriminator_loss_step=0.960, val_discriminator_loss=1.600, val_

Epoch 3:   0%| | 0/4 [00:00<?, ?it/s, v_num=o8yp, train_generator_loss_step=1.250, train_discriminator_loss_step=0.960, val_discriminator_loss=1.870, val_generatotorch.Size([128, 7])
Epoch 3:  25%|▎| 1/4 [00:18<00:56, 18.93s/it, v_num=o8yp, train_generator_loss_step=1.140, train_discriminator_loss_step=0.989, val_discriminator_loss=1.870, val_torch.Size([128, 7])
Epoch 3:  50%|▌| 2/4 [00:18<00:18,  9.48s/it, v_num=o8yp, train_generator_loss_step=1.110, train_discriminator_loss_step=1.010, val_discriminator_loss=1.870, val_torch.Size([89, 7])
Epoch 3:  75%|▊| 3/4 [00:18<00:06,  6.33s/it, v_num=o8yp, train_generator_loss_step=1.050, train_discriminator_loss_step=1.120, val_discriminator_loss=1.870, val_

Epoch 4:   0%| | 0/4 [00:00<?, ?it/s, v_num=o8yp, train_generator_loss_step=1.050, train_discriminator_loss_step=1.120, val_discriminator_loss=2.220, val_generatotorch.Size([128, 7])
Epoch 4:  25%|▎| 1/4 [00:18<00:56, 18.76s/it, v_num=o8yp, train_generator_loss_step=0.971, train_discriminator_loss_step=1.110, val_discriminator_loss=2.220, val_torch.Size([128, 7])
Epoch 4:  50%|▌| 2/4 [00:18<00:18,  9.45s/it, v_num=o8yp, train_generator_loss_step=0.969, train_discriminator_loss_step=1.150, val_discriminator_loss=2.220, val_torch.Size([89, 7])
Epoch 4:  75%|▊| 3/4 [00:18<00:06,  6.30s/it, v_num=o8yp, train_generator_loss_step=0.888, train_discriminator_loss_step=1.180, val_discriminator_loss=2.220, val_

Epoch 5:   0%| | 0/4 [00:00<?, ?it/s, v_num=o8yp, train_generator_loss_step=0.888, train_discriminator_loss_step=1.180, val_discriminator_loss=2.430, val_generatotorch.Size([128, 7])
Epoch 5:  25%|▎| 1/4 [00:18<00:55, 18.65s/it, v_num=o8yp, train_generator_loss_step=0.894, train_discriminator_loss_step=1.160, val_discriminator_loss=2.430, val_torch.Size([128, 7])
Epoch 5:  50%|▌| 2/4 [00:18<00:18,  9.33s/it, v_num=o8yp, train_generator_loss_step=0.798, train_discriminator_loss_step=1.230, val_discriminator_loss=2.430, val_torch.Size([89, 7])
Epoch 5:  75%|▊| 3/4 [00:18<00:06,  6.22s/it, v_num=o8yp, train_generator_loss_step=0.790, train_discriminator_loss_step=1.270, val_discriminator_loss=2.430, val_

Epoch 6:   0%| | 0/4 [00:00<?, ?it/s, v_num=o8yp, train_generator_loss_step=0.790, train_discriminator_loss_step=1.270, val_discriminator_loss=2.670, val_generatotorch.Size([128, 7])
Epoch 6:  25%|▎| 1/4 [00:18<00:55, 18.53s/it, v_num=o8yp, train_generator_loss_step=0.775, train_discriminator_loss_step=1.270, val_discriminator_loss=2.670, val_torch.Size([128, 7])
Epoch 6:  50%|▌| 2/4 [00:18<00:18,  9.27s/it, v_num=o8yp, train_generator_loss_step=0.757, train_discriminator_loss_step=1.290, val_discriminator_loss=2.670, val_torch.Size([89, 7])
Epoch 6:  75%|▊| 3/4 [00:18<00:06,  6.18s/it, v_num=o8yp, train_generator_loss_step=0.715, train_discriminator_loss_step=1.300, val_discriminator_loss=2.670, val_

Epoch 7:   0%| | 0/4 [00:00<?, ?it/s, v_num=o8yp, train_generator_loss_step=0.715, train_discriminator_loss_step=1.300, val_discriminator_loss=2.780, val_generatotorch.Size([128, 7])
Epoch 7:  25%|▎| 1/4 [00:19<00:58, 19.45s/it, v_num=o8yp, train_generator_loss_step=0.692, train_discriminator_loss_step=1.330, val_discriminator_loss=2.780, val_torch.Size([128, 7])
Epoch 7:  50%|▌| 2/4 [00:19<00:19,  9.77s/it, v_num=o8yp, train_generator_loss_step=0.652, train_discriminator_loss_step=1.310, val_discriminator_loss=2.780, val_torch.Size([89, 7])
Epoch 7:  75%|▊| 3/4 [00:19<00:06,  6.51s/it, v_num=o8yp, train_generator_loss_step=0.719, train_discriminator_loss_step=1.300, val_discriminator_loss=2.780, val_


Validation DataLoader 0:   0%|                                                                                                              | 0/1 [00:00<?, ?it/s]
Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x131895f70>
Traceback (most recent call last):
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1510, in __del__
    self._shutdown_workers()
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1474, in _shutdown_workers
    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/multiprocessing/process.py", line 149, in join
    res = self._popen.wait(timeout)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/multiprocessing/popen_fork.py", line 40, in wait
    if not wait([self.sentinel], timeout):
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt:
Traceback (most recent call last):
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
KeyboardInterrupt
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/selectors.py", line 416, in select
    fd_event_list = self._selector.poll(timeout)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 39763) is killed by signal: Interrupt: 2.
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1163, in _try_get_data
    data = self._data_queue.get(timeout=timeout)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/multiprocessing/queues.py", line 113, in get
    if not self._poll(timeout):
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/multiprocessing/connection.py", line 257, in poll
    return self._poll(timeout)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/multiprocessing/connection.py", line 424, in _poll
    r = wait([self], timeout)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/multiprocessing/connection.py", line 931, in wait
    ready = selector.select(timeout)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/torch/utils/data/_utils/signal_handling.py", line 66, in handler
    _error_if_any_worker_fails()
RuntimeError: DataLoader worker (pid 39806) is killed by signal: Interrupt: 2.
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/Users/nehcream/Documents/Workspace/Active/AI-SPARK-Challenge/train.py", line 139, in <module>
    main(config)
  File "/Users/nehcream/Documents/Workspace/Active/AI-SPARK-Challenge/train.py", line 90, in main
    trainer.fit(
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 608, in fit
    call._call_and_handle_interrupt(
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 650, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1112, in _run
    results = self._run_stage()
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1191, in _run_stage
    self._run_train()
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py", line 1214, in _run_train
    self.fit_loop.run()
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py", line 267, in advance
    self._outputs = self.epoch_loop.run(self._data_fetcher)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/loops/loop.py", line 199, in run
    self.advance(*args, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 187, in advance
    batch = next(data_fetcher)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py", line 184, in __next__
    return self.fetching_function()
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py", line 265, in fetching_function
    self._fetch_next_batch(self.dataloader_iter)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/utilities/fetching.py", line 280, in _fetch_next_batch
    batch = next(iterator)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py", line 569, in __next__
    return self.request_next_batch(self.loader_iters)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/pytorch_lightning/trainer/supporters.py", line 581, in request_next_batch
    return apply_to_collection(loader_iters, Iterator, next)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/lightning_utilities/core/apply_func.py", line 51, in apply_to_collection
    return function(data, *args, **kwargs)
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 681, in __next__
    data = self._next_data()
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1359, in _next_data
    idx, data = self._get_data()
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1325, in _get_data
    success, data = self._try_get_data()
  File "/opt/homebrew/Caskroom/miniconda/base/envs/datascience/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1176, in _try_get_data
    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e
RuntimeError: DataLoader worker (pid(s) 39806) exited unexpectedly